{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In class exercises for ML tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data from eeg study\n",
    "* This time I've kept in data across a 1s window from many electrodes (20) sampled at 250Hz, so now we have a [960, 20, 250] matrix that contains data from all 960 trials, 20 electrodes, and over a 1s window following stimulus onset\n",
    "* Also read in a \"cond_labels\" vector that has 960 0's and 1's to mark trials from the two experimental conditions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Support vector classifier\n",
    "from sklearn.svm import SVC \n",
    "\n",
    "# also define the default font we'll use for figures. \n",
    "fig_font = {'fontname':'Arial', 'size':'20'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'cond_labels is not a file in the archive'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-130f9154fe8b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0meeg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sr'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0meeg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tx'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0meeg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cond_labels'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# shape of data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    237\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 239\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not a file in the archive\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'cond_labels is not a file in the archive'"
     ]
    }
   ],
   "source": [
    "# load the data...\n",
    "eeg = np.load('class_demo_eeg.npz')\n",
    "\n",
    "# get the different arrays like this...\n",
    "eeg['data']\n",
    "eeg['sr']\n",
    "eeg['tx']\n",
    "eeg['cond_labels']\n",
    "\n",
    "# shape of data\n",
    "print('Shape of the big eeg data set: ', eeg['data'].shape)\n",
    "\n",
    "# and if you want to save some typing, especially because we only have a few variables, you reassign the different arrays like this\n",
    "data = eeg['data']\n",
    "sr = eeg['sr']\n",
    "tx = eeg['tx']\n",
    "cond_labels = eeg['cond_labels']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the mean across the first dimension (trials) and then plot the mean response across time in each of the 20 electrodes on one axis\n",
    "\n",
    "* Might need to transpose the data into a Time x Electrode format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the mean over the first dim\n",
    "mean_data = np.mean(data, axis=0)\n",
    "print(mean_data.shape)\n",
    "\n",
    "# plot\n",
    "plt.plot(tx, mean_data.T)\n",
    "plt.xlabel('Time(msec)', **fig_font)\n",
    "plt.ylabel('Response (mV)', **fig_font)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## That gives you an idea about what the pattern of data looks like across electrodes. \n",
    "* Next, take the mean across time, so you have a 960 x 20 matrix \n",
    "* Use the cond_labels vector to sort the data based on condition (so you have two 480 x 20 matrices)\n",
    "* Do classification to see if you can decode the experimental condition\n",
    "* Remember - break up your data into independent training and testing sets\n",
    "* Set C to a small number if this is taking a long time..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean of 3rd dim (time)\n",
    "all_data = np.mean(data, axis=2)\n",
    "\n",
    "# sort data into two conditions\n",
    "data0 = all_data[cond_labels==0,:]\n",
    "data1 = all_data[cond_labels==1,:]\n",
    "\n",
    "# define how much training data to use\n",
    "pcnt_trn = .9\n",
    "num_train_per_cond = int(np.floor(pcnt_trn * data0.shape[0]))\n",
    "\n",
    "# then separate out training and test data\n",
    "trn_data = np.vstack( (data0[:num_train_per_cond,:], data1[:num_train_per_cond,:])  )\n",
    "trn_labels = np.hstack((np.zeros(num_train_per_cond), np.ones(num_train_per_cond)))\n",
    "\n",
    "# then assign the test set and test set labels\n",
    "tst_data = np.vstack( (data0[num_train_per_cond:,:], data1[num_train_per_cond:,:])  )\n",
    "num_tst_per_cond = int(tst_data.shape[0]/2)\n",
    "tst_labels = np.hstack((np.zeros(num_tst_per_cond), np.ones(num_tst_per_cond)))\n",
    "\n",
    "# SVC \n",
    "model = SVC(kernel='linear', C=1)\n",
    "\n",
    "# then fit the model to our training data by passing in the data matrix + a list of labels that denotes the \n",
    "# experimental condition for each trial\n",
    "model.fit(trn_data, trn_labels)\n",
    "\n",
    "# then predict\n",
    "class_labels = model.predict(tst_data)\n",
    "\n",
    "# Then just compute our classification accuracy by comparing the predicted labels to the ground truth\n",
    "class_acc = np.sum(class_labels==tst_labels) /  tst_data.shape[0]\n",
    "print('Classification accuracy with a SVM is: ', class_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now try doing this across timepoints!\n",
    "* First do a time window based on where you think there is nice separation in the responses across electrodes (look at the data that you plotted above)...maybe try 300-400msec post stim\n",
    "* Then you can try timepoint x timepoint or a moving window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over time\n",
    "# for t in np.arange(data.shape[2]):\n",
    "    \n",
    "    \n",
    "# or, just for a demo, pick out a temporal window over which to average\n",
    "t_win = (tx>=300) & (tx<400)\n",
    "\n",
    "# mean of 3rd dim (time)\n",
    "all_data = np.mean(data[:,:,t_win], axis=2)\n",
    "\n",
    "# sort data into two conditions\n",
    "data0 = all_data[cond_labels==0,:]\n",
    "data1 = all_data[cond_labels==1,:]\n",
    "\n",
    "# define how much training data to use\n",
    "pcnt_trn = .9\n",
    "num_train_per_cond = int(np.floor(pcnt_trn * data0.shape[0]))\n",
    "\n",
    "# then separate out training and test data\n",
    "trn_data = np.vstack( (data0[:num_train_per_cond,:], data1[:num_train_per_cond,:])  )\n",
    "trn_labels = np.hstack((np.zeros(num_train_per_cond), np.ones(num_train_per_cond)))\n",
    "\n",
    "# then assign the test set and test set labels\n",
    "tst_data = np.vstack( (data0[num_train_per_cond:,:], data1[num_train_per_cond:,:])  )\n",
    "num_tst_per_cond = int(tst_data.shape[0]/2)\n",
    "tst_labels = np.hstack((np.zeros(num_tst_per_cond), np.ones(num_tst_per_cond)))\n",
    "\n",
    "# SVC \n",
    "model = SVC(kernel='linear', C=1)\n",
    "\n",
    "# then fit the model to our training data by passing in the data matrix + a list of labels that denotes the \n",
    "# experimental condition for each trial\n",
    "model.fit(trn_data, trn_labels)\n",
    "\n",
    "# then predict\n",
    "class_labels = model.predict(tst_data)\n",
    "\n",
    "# Then just compute our classification accuracy by comparing the predicted labels to the ground truth\n",
    "class_acc = np.sum(class_labels==tst_labels) /  tst_data.shape[0]\n",
    "print('Classification accuracy with a SVM is: ', class_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
